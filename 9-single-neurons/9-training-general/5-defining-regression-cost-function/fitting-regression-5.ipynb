{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a Linear Regression Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we discussed our formula for linear regression, $y$ = $mx + b$.  And we saw how we can use our SciKit Learn library to discover the estimated values for $m$ and $b$.  But how does SciKit Learn, or any linear regression model come up with these numbers.  In this lesson we'll start finding out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How SciKit Learn \"Fits\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now SciKit Learn finds values for $m$ and $b$ when we *fit* our linear regression model to the data.  Let's again see how we do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [800, 1500, 2000, 3500, 4000]\n",
    "sklearn_inputs = [ [800], \n",
    "    [1500],\n",
    "    [2000],\n",
    "    [3500],\n",
    "    [4000] ]\n",
    "outcomes = [330, 780, 1130, 1310, 1780]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regression = LinearRegression()\n",
    "# create the initial model\n",
    "regression.fit(sklearn_inputs, outcomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we call the `fit` function, the model has come up with numbers for both the coefficient and the intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.38675261])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153.26385079539216"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we `fit` the line, what we are trying to do is find the line that best matches the data that we pass through the model - our inputs and outcomes.  By \"best matches\" we mean, the line that comes closes to the data.  So how do we get a line that comes closes to the data?\n",
    "\n",
    "These are the steps.\n",
    "\n",
    "1. Start with an initial model: that is, initial values for $m$ and $b$, these numbers can be anything.\n",
    "2. Evaluate a model by calculating how close the model predicts our observed observed data\n",
    "3. Update the parameters of our linear regression model and evaluate this updated model\n",
    "4. Stop when we have a linear regression model that comes as close as possible to the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the rest of this lesson, we'll examine the first two steps, building an initial model and evaluating the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the initial model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's easy enough to build an initial model.  All we need to do is select some numbers for our values of $m$ and $b$.  So we'll choose $m = .6$ and $b = 100$.  Which means that our function is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y = .6x + 100$$ \n",
    "or \n",
    "\n",
    "$$tshirt\\_sales = .6*ad\\_spend + 100$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what this model looks like next to our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'https://plot.ly/~JeffKatzy/172'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graph import plot, trace_values\n",
    "import plotly.plotly as py\n",
    "data_trace = trace_values(inputs, outcomes)\n",
    "predictions = list(map(lambda ad_sale: .6*ad_sale + 100, inputs))\n",
    "predictions_trace = trace_values(inputs, predictions, mode = 'lines', name = 'predictions')\n",
    "py.plot([data_trace, predictions_trace])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So remember that the blue dots represent the actual data of each advertising budget dollars and it's corresponding monthly sales.  And the orange line is the predictions from our initial linear regression model.\n",
    "\n",
    "Our goal is that our model predicts our observed -- or graphically that our orange line comes close to the blue dots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the model by seeing how close our predicted outcomes come to the actual observed outcomes.  The closer our model is to predicting the actual data, the better.  Let's make this closeness more visual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://plot.ly/~JeffKatzy/178'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from error import error_line_traces\n",
    "errors = [-250, -220, -170, -890, -720]\n",
    "error_traces = error_line_traces(inputs, outcomes, errors)\n",
    "py.plot([data_trace, predictions_trace, *error_traces])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now each red line represents the difference between the t shirt sales that our model predicts for a given amount of advertising spent, and what we actually observed.  \n",
    "\n",
    "Let's focus in on that first red line.  Our model predicts t-shirt sales of 400 while the observed t-shirt sales was 330.  The red line shows the difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's turn these red lines into a number.  We do this by calculating the *difference* between the actual data and what our model expects.  We call this difference our **error**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> error = actual - expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now just like we had standard symbols to represent our components of linear regression (y = mx + b), we also have symbols to represent the formula above. Here they are: \n",
    "\n",
    "> * $y^{(i)}$ represent our actual, or observed target variables\n",
    "> * $\\bar{y^{(i)}}$ (pronounced y hat) represents our predicted output \n",
    "> * $\\epsilon$ (epsilon) represents error\n",
    "> \n",
    "Let's explore this a bit by looking at our formula for error at a given point.  \n",
    "> \n",
    "> $\\epsilon^{i} = y^{(i)} - \\hat{y^{(i)}}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this just says that the error at given point equals the outcome we observed at that observation minus the outcome we predicted for that observation. \n",
    "\n",
    "Let's calculate the errors of our initial model with respect to our observed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$tshirt\\_sales = .6*ad\\_spend + 100$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|ad spending    |t-shirts| predicted t-shirts |  error |\n",
    "| ------------- |:-----:|:-------------------:| :-----:| \n",
    "|    800        | 330  | 580  | -250|\n",
    "|    1500       | 780 | 1000| -220|\n",
    "|    2000      | 1130 | 1300| -170|\n",
    "|    3500      | 1310 | 2200| -890|\n",
    "|    4000      | 1780 | 2500| -720|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2250"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = [-250, -220, -170, -890, -720]\n",
    "sum(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so we can see that our error for the first point is $330 - 580 = -250$.  And we can even calculate the **total error** of our model, just by adding these numbers up. \n",
    "\n",
    "$$total\\_error = -250, -220, -170, -890, -720 = - 2250 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we don't really care whether our numbers are positive or negative, what we care is whether just how close the number is to zero.  The closer the number is to zero the better we do.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One small problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now one way to discover if our model is any good is to compare it with other linear regression models.  So let's change the value of our linear regression model from $tshirt\\_sales = .6*ad\\_spend + 100$ to the following:\n",
    "\n",
    "$$tshirt\\_sales = .4*ad\\_spend + 100$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://plot.ly/~JeffKatzy/176'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def updated_model_with_errors(parameter):\n",
    "    predictions = list(map(lambda ad_spend: parameter*ad_spend + 100, inputs))\n",
    "    predictions_trace = trace_values(inputs, predictions, 'lines', name = 'predictions')\n",
    "    y_values_y_hats = list(zip(outcomes, predictions))\n",
    "    errors = list(map(lambda pair: pair[0] - pair[1], y_values_y_hats))\n",
    "    error_traces = error_line_traces(inputs, outcomes, errors)\n",
    "    return py.plot([data_trace, predictions_trace] + error_traces)\n",
    "\n",
    "parameter = .4\n",
    "# feel free to change the parameter to .6 or other values of m and then re-execute the function\n",
    "updated_model_with_errors(parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's recalculate our total error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we calculate the error at each data point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|ad spending    |t-shirts| predicted t-shirts |  error |\n",
    "| ------------- |:-----:|:-------------------:| :-----:| \n",
    "|    800        | 330  | 420  | -90|\n",
    "|    1500       | 780 | 700| 80|\n",
    "|    2000      | 1130 | 900| 230|\n",
    "|    3500      | 1310 | 1500| -190|\n",
    "|    4000      | 1780 | 1700| 80|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we add up all of our points we get a total error of 110.  But take a look at the total error after just adding up our first two points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-90 + 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somehow our total error after two points is closer to zero than our total error after one point.  The positive and negative numbers are cancelling each other out.  This isn't good.  We want our total error to increase each time that our predicted output differs from our observed output.  We don't want our errors to cancel each other out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fix this by simply making each error positive, which we do by squaring the error.  \n",
    "\n",
    "$$sum\\_of\\_squared\\_errors = -90^2 + 80^2 + 230^2 + -190^2 + -80^2 $$\n",
    "\n",
    "$$ = 8100 +  6400 + 52900 + 36100 + 6400 $$\n",
    "\n",
    "$$ = 109,900 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now, because each individual squared error is always positive, our errors will not cancel each other out.  We call this the **residual sum of the squared** (RSS). In machine learning and statistics, residual is just another word for error.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now that we have expressed how well a model predicts our data with RSS, we can start to compare models to data.  For example, we go back and calculate the RSS for our first model of \n",
    "\n",
    "$$tshirt\\_sales = .6*ad\\_spend + 100$$ we get:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|ad spending    |t-shirts| predicted t-shirts |  squared error |\n",
    "| ------------- |:-----:|:-------------------:| :-----:| \n",
    "|    800        | 330  | 580  | 62500|\n",
    "|    1500       | 780 | 1000| 48400|\n",
    "|    2000      | 1130 | 1300| 28900|\n",
    "|    3500      | 1310 | 2200| 792100|\n",
    "|    4000      | 1780 | 2500| 518400|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the sum of the squared errors, or the RSS for this model is 1,450,300."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our first model of $tshirt\\_sales = .4*ad\\_spend + 100$ had an RSS of 109,900 and the second model of $tshirt\\_sales = .6*ad\\_spend + 100$ has an RSS of 1,050,300 .  So because the RSS is smaller with our first model than our second model,  our first model is better fit to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we saw how to evaluate a machine learning model.  We do this by seeing how well the model matches the actual data.  The closer the model is to the data, the better our model.  \n",
    "\n",
    "We can summarize how well the model fits the data by calculating the error at each of our actual data points, where our $error =  actual - expected$.  We add up the error at each datapoint to calculate the **total error**.\n",
    "\n",
    "Then we saw that **total error** has a flaw, where the errors can cancel each other out when some errors are positive and others are negative.  To fix this, we make each of our errors positive by squaring each error.  And then we add up our squared errors to calculate the **residual sum of the squares** (RSS).  We can use our RSS score to try different models and then choose the one with the lowest score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
