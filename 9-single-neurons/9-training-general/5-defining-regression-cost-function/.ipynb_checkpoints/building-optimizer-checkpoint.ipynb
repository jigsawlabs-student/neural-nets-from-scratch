{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing our Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we'll build out the component that finds the hypothesis function that minimizes the output of our loss component.  We'll "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading our classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hypothesis():\n",
    "    def __init__(self, coef_ = None, intercept_ = None, x_values = None):\n",
    "        self.coef_ = coef_\n",
    "        self.intercept_ = intercept_\n",
    "        self.x_values = x_values\n",
    "    \n",
    "    def predict(self):\n",
    "        return [self.predict_value(value) for value in self.x_values]\n",
    "    \n",
    "    def predict_value(self, value):\n",
    "        return self.coef_*value + self.intercept_\n",
    "    \n",
    "    def trace(self, mode = 'lines', name=None, text = []):\n",
    "        coef_text = f\"y = {self.coef_}x\"\n",
    "        intercept_text = f\" + {self.intercept_}\"\n",
    "        default_text = coef_text + intercept_text if self.intercept_ else coef_text\n",
    "        text = name or default_text\n",
    "        return {'x': self.x_values, 'y': self.predict(), 'mode': mode, 'name': name, 'text': text}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating our Optimizer Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, we left in the beginning components to our Optimizer class.  \n",
    "\n",
    "Let's take a look at the `__init__` function.  Note that the optimizer begins by taking in our data of the actual `x_values` and `y_values`.  It also takes in the y-intercept value.  This is because we will not tackle the more complicated problem of having our Optimizer find both parameters, it will only find the coefficient.\n",
    "\n",
    "The `start`, `stop` and `step_count` parameters will be explained further down below.  So will the `steps` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, x_values, y_values, intercept, start, stop, step_count):\n",
    "        self.x_values = x_values\n",
    "        self.y_values = y_values\n",
    "        self.intercept = intercept\n",
    "        self.start = start\n",
    "        self.stop = stop\n",
    "        self.step_count = step_count\n",
    "        \n",
    "    def steps(self):\n",
    "        step_size = (self.stop - self.start)/self.step_count\n",
    "        self.steps = []\n",
    "        for count in list(range(0, self.step_count)):\n",
    "            self.steps.append(self.start + count*step_size)\n",
    "        return self.steps\n",
    "    \n",
    "    def set_hypotheses(self):\n",
    "        coefs = self.steps\n",
    "        self.hypotheses = [Hypothesis(coef, self.intercept, self.x_values) for coef in coefs]\n",
    "    \n",
    "    def set_losses(self):\n",
    "        self.losses = [Loss(hypothesis, self.x_values, self.y_values) for hypothesis in self.hypotheses]\n",
    "        \n",
    "    def find_min(self):\n",
    "        return min(self.losses, key = lambda loss: loss.rss())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the goal of our optimizer is to find the value for our coefficient parameter that minimize the our `rss`.  The way that we'll do this is to create a list of Hypothesis instances, each with a sequential value of `m`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our first Hypothesis could be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intercept = 153\n",
    "# coef = .01\n",
    "# x_values = [800, 1500, 2000, 3500, 4000]\n",
    "hyp = Hypothesis(coef, intercept, x_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the second Hypothesis instance would have the same data except a slightly different coefficient parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intercept = 153\n",
    "# coef = .01\n",
    "# x_values = [800, 1500, 2000, 3500, 4000]\n",
    "hyp = Hypothesis(coef, intercept, x_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create a list of these, and then use our Loss class to find the hypothesis with the smallest one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that's where our steps method enters the picture: it generates a list of $m$ values to then pass through to create a list of Hypothesis instances.  To do so we just need to tell our Optimizer of a starting point, a stopping point, and a step size.  Let's see this in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = 153\n",
    "coef = .01\n",
    "start = 0\n",
    "stop = 1\n",
    "step_number = 100\n",
    "x_values = [800, 1500, 2000, 3500, 4000]\n",
    "outcomes = [330, 780, 1130, 1310, 1780]\n",
    "optimizer = Optimizer(x_values, outcomes, intercept, start, stop, step_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have a list of steps.  Each one of these could be a different value for `m`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.steps()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our steps to create a number of Hypothesis instances, each with the same input values and y-intercept, but a different coefficient.  If you look at the `set_hypotheses` step, you'll that it is responsible for creating a list of `hypotheses`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.set_hypotheses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a list of hypotheses, each with a different coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Hypothesis at 0x10bbe12b0>,\n",
       " <__main__.Hypothesis at 0x10bbe1630>,\n",
       " <__main__.Hypothesis at 0x10bbe1470>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.hypotheses[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[hyp.coef_ for hyp in optimizer.hypotheses[0:9]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have an optimizer class, that can create a number of Hypotheses instances, each with a different coefficient.  What's left is to calculate the `rss` for each of these Hypotheses instances, and find the instance with the lowest `rss`.  \n",
    "\n",
    "Our hypotheses instances don't have the capability to calculate the `rss`.  That functionality lies with our `Loss` instances.  First copy and paste the Loss class below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss():\n",
    "    def __init__(self, hypothesis, x_values, y_values):\n",
    "        self.hypothesis = hypothesis\n",
    "        self.x_values = x_values\n",
    "        self.y_values = y_values\n",
    "        \n",
    "    def errors(self):\n",
    "        expecteds = self.hypothesis.predict()\n",
    "        pairs = list(zip(self.y_values, expecteds))\n",
    "        return [actual - expected for actual, expected in pairs]\n",
    "    \n",
    "    def squared_errors(self):\n",
    "        return [error**2 for error in self.errors()]\n",
    "    \n",
    "    def rss(self):\n",
    "        return sum(self.squared_errors())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " So in the `set_losses` method, use each of the hypothesis instances to create a list of Loss instances, and assign these loss instances to an attribute called `losses`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Loss at 0x10bc185c0>,\n",
       " <__main__.Loss at 0x10bc185f8>,\n",
       " <__main__.Loss at 0x10bc18630>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.set_losses()\n",
    "optimizer.losses[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the losses should store the related hypothesis instances and should also store the x_values and y_values of the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hypothesis': <__main__.Hypothesis at 0x10bbe12b0>,\n",
       " 'x_values': [800, 1500, 2000, 3500, 4000],\n",
       " 'y_values': [330, 780, 1130, 1310, 1780]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.losses[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[loss.hypothesis.coef_ for loss in optimizer.losses[0:9]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now write a method called `find_min` that returns the Loss object with the lowest `rss`.  From there, we can find the related Hypothesis instance, and it's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'coef_': 0.39, 'intercept_': 153, 'x_values': [800, 1500, 2000, 3500, 4000]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = optimizer.find_min()\n",
    "loss.hypothesis.__dict__\n",
    "\n",
    "# {'coef_': 0.39, 'intercept_': 153, 'x_values': [800, 1500, 2000, 3500, 4000]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the hypothesis that minimizes our RSS the hypothesis with a coefficient of .39.  This is within one one-hundredth of what we calculated with SKLearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
