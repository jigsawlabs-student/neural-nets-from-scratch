{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous lessons we learned about machine learning in general.  We saw that in machine learning, we look at what occured with past observations, and from there find a hypothesis function to predict what will occur going forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sounds a bit like the way humans learn, doesn't it?\n",
    "\n",
    "Neural networks were inspired by human learning.  And more specifically, by representing the mechanisms of human learning as a machine learning algorithm called an artificial neural network.  In this lesson, we'll begin to make the comparisons between the mechanisms between human learning and those in an artificial neural neural network.  \n",
    "\n",
    "Let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From network to neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an image of part of the human brain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://storage.cloud.google.com/curriculum-assets/nn-from-scratch/mit-neurons.jpg\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the blue spheres above is the cell body of a different neuron, and the combination of different neurons lighting up is what forms the thoughts and decisions that humans make.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that these neurons are touching each other, and can imagine that the lighting up or not of one neuron influences whether or not a connected neuron lights up.  \n",
    "\n",
    "We'll talk about an entire neural network in future lessons.  That's enough for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, let's focus on a single neuron.  We'll first learn the hypothesis function of a single neuron, and then it's training procedure.  From there, we can better understand how an entire neural network works. \n",
    "\n",
    "Below is a picture of a single neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://storage.cloud.google.com/curriculum-assets/nn-from-scratch/neuron-img.jpg\" width=\"30%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purplish circle in the neuron is the neuron's cell body.  And the neuron takes in various inputs via the squiggly lines to left - called dendrites.  And based on these inputs it sends or does not send a signal via the axon at the top right.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see this again through an artificial neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://storage.cloud.google.com/curriculum-assets/nn-from-scratch/simple-neuron.png\" width=\"60%\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So just like our real neuron, our artificial neuron takes in multiple inputs and has a single output.  For now, the neuron's output will be either a zero or a one -- to represent being activated or not.  \n",
    "\n",
    "Let's imagine that we are using the collection of neurons in a neural network to determine if we should eat a piece of food.  And that our single neuron above is in charge of interpreting if a piece of food contains sugar. To determine if sugar is present, it considers the amount that the food tastes sweet and the amount that it smells sweet . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://storage.googleapis.com/curriculum-assets/nn-from-scratch/perceptron-sugar.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple neuron: Inputs and Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we could turn our artificial neuron above into code with a function.  In the function below, the neuron takes inputs of the smell and taste, and outputs a number to indicate if the food contains sugar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sugar_neuron_v1(tastes_sweet_amount, smells_sweet_amount):\n",
    "    return tastes_sweet_amount + smells_sweet_amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for example, if we have the features of a piece of chocolate, and input it into the neuron, we might get the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dark chocolate sweetness \n",
    "# tastes sweet: 6. smells sweet: 3.\n",
    "choc_tastes_swt = 9 \n",
    "choc_smells_swt = 5\n",
    "\n",
    "sugar_neuron_v1(choc_tastes_swt, choc_smells_swt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the significance of this number 14?  Well you could imagine that if the return value is a certain number, the neuron activiates to predict that there is sugar.  Let's update our function to make this more explicit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sugar_neuron_v2(tastes_sweet_amount, smells_sweet_amount):\n",
    "    return tastes_sweet_amount + smells_sweet_amount - 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We updated the function above so that we predict a food contains sugar only if the neuron outputs a number greater than zero.  \n",
    "\n",
    "Now trying our `sugar_neuron` out on our chocolate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choc_tastes_swt = 9\n",
    "choc_smells_swt = 3\n",
    "\n",
    "sugar_neuron_v2(choc_tastes_swt, choc_smells_swt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Above**, we predict that there *is* sugar as 6 is greater than 0.  \n",
    "\n",
    "> **Below**, our neuron predicts there is not sugar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water_taste = 0\n",
    "water_smell = 0\n",
    "\n",
    "sugar_neuron_v2(water_taste, water_smell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look again at the code in our neuron.\n",
    "\n",
    "```python\n",
    "def sugar_neuron_v2(tastes_sweet_amount, smells_sweet_amount):\n",
    "    return tastes_sweet_amount + smells_sweet_amount - 6\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call that last term of `-6` our bias.  It acts as a sort of counterweight to the rest of the function, whereby we only predict that food has sugar if the sum outweighs the bias term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use our machine learning terms, what we have just described is our hypothesis function for our neuron.  And we can represent our hypothesis function above as the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "  h(x)=\\left\\{\n",
    "  \\begin{array}{@{}ll@{}}\n",
    "    sugar, & \\text{if}\\ x_1 + x_2 + bias > 0 \\\\\n",
    "    no sugar, & \\text{otherwise}\n",
    "  \\end{array}\\right.\n",
    "\\end{equation} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where $x_1$ and $x_2$ represent the features, taste and smell, of a food item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Developing our Pallete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's update our hypothesis function above.  We'll do so by setting taste to be worth twice as much as smell.  We also change our bias to be -18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweetness_neuron_v3(tastes_sweet_amount, smells_sweet_amount): \n",
    "    return 2*tastes_sweet_amount + 1*smells_sweet_amount - 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So notice above, we don't just add up our evidence, but also attach *weights* to different attributes.  We weight the taste twice as much as the smell.  So we could represent this function above as: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "  h(x)=\\left\\{\n",
    "  \\begin{array}{@{}ll@{}}\n",
    "    1, & \\text{if}\\ 2x_1 + 1x_2 - 18 > 0  \\\\\n",
    "    0, & \\text{otherwise}\n",
    "  \\end{array}\\right.\n",
    "\\end{equation} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Where $x_1$ is the taste and $x_2$ is smell.\n",
    ">\n",
    "> And 1 represents a prediction of sugar, and 0 is a prediction of no sugar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now begin to break down our hypothesis function for our neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "  h(x)=\\left\\{\n",
    "  \\begin{array}{@{}ll@{}}\n",
    "    1, & \\text{if}\\ 2x_1 + 1x_2 - 18 > 0  \\\\\n",
    "    0, & \\text{otherwise}\n",
    "  \\end{array}\\right.\n",
    "\\end{equation} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main component seems to be the function $2x_1 + 1x_2 - 6$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The linear component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call this the *linear component* or *linear function* of our hypothesis function, and it takes the following form:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$z(x) = w_1x_1 + w_2x_2 + ... w_nx_n + bias$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So above, we name the linear component $z(x)$. And just as before, the function takes in the features of a single observation -- like the taste or smell of sugar in a piece of food."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_component(tastes_sweet_amount, smells_sweet_amount): \n",
    "    return 2*tastes_sweet_amount + 1*smells_sweet_amount - 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we break down this linear function further, we can think of in two parts: the weighted sum and the bias.  \n",
    "\n",
    "* The weighted sum is of the form $w_1x_1 + ... w_n*x_n$.\n",
    "* The bias acts as a counterbalance to the weighted sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's go back to our hypothesis function for the neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "  h(x)=\\left\\{\n",
    "  \\begin{array}{@{}ll@{}}\n",
    "    1, & \\text{if}\\ w_1x_1 + w_2x_2 + ... w_nx_n + bias > 0 \\\\\n",
    "    0, & \\text{otherwise}\n",
    "  \\end{array}\\right.\n",
    "\\end{equation} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think of the `if else` logic as our *activation function*.  This is in charge of the output from the neuron.  Let's represent our activation function in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(z):\n",
    "    if z > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our activation function takes the weighted sum, and if the weighted sum is greater than 0 it returns 1, and if not, it returns 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use both of the functions to make a prediction from our chocolate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "choc_tastes_swt = 9\n",
    "choc_smells_swt = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_component(choc_tastes_swt, choc_smells_swt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation(linear_component(9, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So because the linear component outputs a number greater than 0, our neuron does activate, or fire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we saw the hypothesis function for a single neuron.  We saw that the our hypothesis function consists of two components, the linear component and an activation function.  \n",
    "\n",
    "1. Linear Component\n",
    "\n",
    "Part of the linear component is the weighted sum, where the neuron takes the features of an observation and assigns a corresponding weight to each feature.  The other part of the weighted sum is the bias term, which acts as a counterbalance to the weighted sum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://storage.googleapis.com/curriculum-assets/nn-from-scratch/weighted-sum.png\" width=\"30%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We feed the output fo the linear component into our activation function.  Where our activation function determines the output from our neuron.  Above, our activation function returns a 1 or a 0 based on whether the linear component is greater than 0.  And we coded it as the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(z):\n",
    "    if z > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. The whole hypothesis function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entire hypothesis function looks like the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "  h(x)=\\left\\{\n",
    "  \\begin{array}{@{}ll@{}}\n",
    "    1, & \\text{if}\\ w_1x_1 + w_2x_2 + bias > 0 \\\\\n",
    "    0, & \\text{otherwise}\n",
    "  \\end{array}\\right.\n",
    "\\end{equation} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or in our diagram of an artificial neuron it looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://storage.googleapis.com/curriculum-assets/nn-from-scratch/neuron-general-2.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Where $x_1$ and $x_2$ are the features of an observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or in code, we can write the hypothesis function as the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_component(tastes_sweet_amount, smells_sweet_amount): \n",
    "    return 2*tastes_sweet_amount + 1*smells_sweet_amount - 18\n",
    "\n",
    "def activation(z):\n",
    "    if z > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choc_tastes_swt = 9\n",
    "choc_smells_swt = 3\n",
    "\n",
    "activation(linear_component(choc_tastes_swt, choc_smells_swt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"https://www.jigsawlabs.io/free\" style=\"position: center\"><img src=\"https://storage.cloud.google.com/curriculum-assets/curriculum-assets.nosync/mom-files/jigsaw-labs.png\" width=\"15%\" style=\"text-align: center\"></a>\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
