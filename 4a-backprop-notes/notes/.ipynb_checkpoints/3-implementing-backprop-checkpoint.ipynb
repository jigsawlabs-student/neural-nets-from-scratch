{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pytorch \n",
    "    * matmul\n",
    "    * Using pytorch, can also call the @ symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin(x, w, b): return x@w + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x): return x.clamp_min(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = relu(lin(x_valid, w_1, b1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(xb):\n",
    "    l1 = lin(xb, w1, b1)\n",
    "    l2 = relu(l1)\n",
    "    l3 = lin(l2, w2, b2)\n",
    "    return l3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Perform forward pass "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(output, target):\n",
    "    return (output.squeeze(1) - targ).pow(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse(preds, y_train)\n",
    "# gives us the error, and thus a forward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./forward-pass-sketch.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* At 1:51 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This is great, because then we just need the derivative of each bit on it's own, and then just multiply them all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Derivatives we need to do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. linear layer\n",
    "    * gradient is simply\n",
    "        * gradient of a matrix product, is simply the matrix product with the transpose\n",
    "        * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "[Lesson 8](https://www.youtube.com/watch?v=4u8FxNEDUeg&t=1s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notebook](https://github.com/fastai/course-v3/blob/master/nbs/dl2/02_fully_connected.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
