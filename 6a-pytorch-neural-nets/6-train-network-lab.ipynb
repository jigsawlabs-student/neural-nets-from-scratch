{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Network Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we'll work with a fashion dataset once more.  In working through this lesson, try to only look at past readings if necessary.  The purpose of this lab is to become more familiar with the Pytorch library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll begin by loading up the torch and torchvision modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's download the FashionMNIST dataset using the `datasets` module.  In the `transform` argument set the following:\n",
    "\n",
    "```python\n",
    "transforms.Compose([transforms.ToTensor()])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Check that we downloaded the data properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "train\n",
    "# Dataset FashionMNIST\n",
    "#     Number of datapoints: 60000\n",
    "#     Root location: \n",
    "#     Split: Train\n",
    "#     StandardTransform\n",
    "# Transform: Compose(\n",
    "#                ToTensor()\n",
    "#            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then download the test data.  Apply the same transformation on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Next, check that the split says `test` for our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "test\n",
    "\n",
    "# Dataset FashionMNIST\n",
    "#     Number of datapoints: 10000\n",
    "#     Root location: \n",
    "#     Split: Test\n",
    "#     StandardTransform\n",
    "# Transform: Compose(\n",
    "#                ToTensor()\n",
    "#            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's explore our training data.  Our training data consists of the `data` and the `targets`.  Take a look at the first 10 ten targets in our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# tensor([9, 0, 0, 3, 0, 2, 7, 2, 5, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see what some of the these values equal with the `class_to_idx` method.  Display a dictionary of the clothing items indicated by each target value below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# {'T-shirt/top': 0,\n",
    "#  'Trouser': 1,\n",
    "#  'Pullover': 2,\n",
    "#  'Dress': 3,\n",
    "#  'Coat': 4,\n",
    "#  'Sandal': 5,\n",
    "#  'Shirt': 6,\n",
    "#  'Sneaker': 7,\n",
    "#  'Bag': 8,\n",
    "#  'Ankle boot': 9}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so it looks like here we are asked to identify images of different clothing items.  Let's use matplotlib to display our first image from the training data below.  (We may have to reshape our observation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "# imshow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./fashion-img.png\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's identify what the target is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Reference the target from the `train` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is an `Ankle Boot`, apparently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to train our data in batches of $50$, so import the DataLoader from `torch.utils.data` so we can do so.  Do this for both the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12)\n",
    "\n",
    "trainset = None\n",
    "testset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.batch_size, testset.batch_size\n",
    "# (50, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to build out our neural network.  The network should match the following specifications:\n",
    "\n",
    "* 4 linear layers \n",
    "* Where each linear layer consists of 64 neurons\n",
    "* And the predictions should be made with the `log_softmax` function.  \n",
    "\n",
    "Ok, get going."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We'll import the necessary libraries for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a class called `Net` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "class Net():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the neural net was defined properly below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (W1): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (W2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (W3): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (W4): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(12)\n",
    "\n",
    "net = Net()\n",
    "net\n",
    "\n",
    "# Net(\n",
    "#   (W1): Linear(in_features=784, out_features=64, bias=True)\n",
    "#   (W2): Linear(in_features=64, out_features=64, bias=True)\n",
    "#   (W3): Linear(in_features=64, out_features=64, bias=True)\n",
    "#   (W4): Linear(in_features=64, out_features=10, bias=True)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll select the first observation from the trainset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_observation = trainset.dataset[0][0]\n",
    "\n",
    "first_observation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the data so that there are 784 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 784])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_obs = None\n",
    "reshaped_obs.shape\n",
    "# torch.Size([1, 784])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make a prediction with that first observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5293, -2.9463, -2.5804, -2.4731, -2.2488, -1.7802, -2.5763, -2.2842,\n",
       "         -1.8583, -2.3056]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make prediction here\n",
    "\n",
    "# tensor([[-2.5293, -2.9463, -2.5804, -2.4731, -2.2488, -1.7802, -2.5763, -2.2842,\n",
    "#          -1.8583, -2.3056]], grad_fn=<LogSoftmaxBackward>)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are ten outputs for the first observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(reshaped_obs).shape\n",
    "\n",
    "# torch.Size([1, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `torch.exp` function to convert this first prediction to probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0797, 0.0525, 0.0757, 0.0843, 0.1055, 0.1686, 0.0761, 0.1019, 0.1559,\n",
       "         0.0997]], grad_fn=<ExpBackward>)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# tensor([[0.0797, 0.0525, 0.0757, 0.0843, 0.1055, 0.1686, 0.0761, 0.1019, 0.1559,\n",
    "#          0.0997]], grad_fn=<ExpBackward>)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to train our neural network.  To do so, we'll first need to initialize an optimizer and a loss function.  For the loss function, initialize cross entropy loss from the `nn` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_loss = None\n",
    "x_loss\n",
    "# CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the optimizer, use the Adam optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Set the learning rate to `.0005` and pass through the params from the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.0005\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "adam = None\n",
    "adam\n",
    "# Adam (\n",
    "# Parameter Group 0\n",
    "#     amsgrad: False\n",
    "#     betas: (0.9, 0.999)\n",
    "#     eps: 1e-08\n",
    "#     lr: 0.0005\n",
    "#     weight_decay: 0\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now it's time to write a training loop for the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the following steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9880, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5534, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4873, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3413, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3580, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5083, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2989, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3683, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# move through the dataset 8 times\n",
    "\n",
    "# divide the training set into X_batch and y_batch\n",
    "\n",
    "# zero the gradient\n",
    "\n",
    "# reshape the data so it each observation in a batch has 784 features\n",
    "\n",
    "# make a prediction with the data\n",
    "\n",
    "# calculate the loss\n",
    "\n",
    "# perform backward propagation\n",
    "\n",
    "# use the optimizer to step\n",
    "\n",
    "# print the loss at the end of each epoch\n",
    "\n",
    "\n",
    "    \n",
    "# tensor(0.9880, grad_fn=<NllLossBackward>)\n",
    "# tensor(0.5534, grad_fn=<NllLossBackward>)\n",
    "# tensor(0.4873, grad_fn=<NllLossBackward>)\n",
    "# tensor(0.3413, grad_fn=<NllLossBackward>)\n",
    "# tensor(0.3580, grad_fn=<NllLossBackward>)\n",
    "# tensor(0.5083, grad_fn=<NllLossBackward>)\n",
    "# tensor(0.2989, grad_fn=<NllLossBackward>)\n",
    "# tensor(0.3683, grad_fn=<NllLossBackward>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating our Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get a sense of how our neural network performed.  First make  predictions on the observations in the testset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We may need to call `float` on our testset to pass through the correct type of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.4961e-08, 1.2412e-05, 4.5766e-09, 9.3961e-07, 1.2311e-06, 9.5997e-04,\n",
       "         4.3604e-08, 4.5264e-03, 2.0135e-05, 9.9448e-01]],\n",
       "       grad_fn=<ExpBackward>)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(predictions_test[:1])\n",
    "\n",
    "# tensor([[4.4961e-08, 1.2412e-05, 4.5766e-09, 9.3961e-07, 1.2311e-06, 9.5997e-04,\n",
    "#          4.3604e-08, 4.5264e-03, 2.0135e-05, 9.9448e-01]],\n",
    "#        grad_fn=<ExpBackward>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the highest probability is for the last class, 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use the `argmax` function to see the labels predicted for each observation.  \n",
    "\n",
    "> Use `axis = 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_predictions = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_predictions[:10]\n",
    "\n",
    "# tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our neural network in action.  This is our fifth image in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x138d52350>"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(test[4][0].view(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_predictions[4]\n",
    "\n",
    "# tensor(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T-shirt/top': 0,\n",
       " 'Trouser': 1,\n",
       " 'Pullover': 2,\n",
       " 'Dress': 3,\n",
       " 'Coat': 4,\n",
       " 'Sandal': 5,\n",
       " 'Shirt': 6,\n",
       " 'Sneaker': 7,\n",
       " 'Bag': 8,\n",
       " 'Ankle boot': 9}"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking good so far.  Next, check the accuracy of our neural network on our testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8303"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# 0.8303"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that our neural network identifies $.83$ of the data correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we trained a neural network in Pytorch.  Nice work!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
