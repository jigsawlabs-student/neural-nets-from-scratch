{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with the Chain Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last lesson, we saw how we can use the derivative to find the rate of change of a composite function.  We learned about this our cost function is itself a composite function:\n",
    "\n",
    "$J(w, b) = (y -  \\sigma(z(w, b)))^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that to find the parameters of $w$ and $b$, we want to see how the output of our cost function $J(w, b)$ changes as we change $w$ and $b$, but this affect is indirect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeing the issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to see this, is simply to code out the cost function of our neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sigmoid(val):\n",
    "    sig = 1/(1 + np.exp(-val))\n",
    "    print('sigma = ', sig)\n",
    "    return sig \n",
    "\n",
    "def z(x, w, b):\n",
    "    z_calc = w*x + b \n",
    "    print('z = ', z_calc)\n",
    "    return z_calc\n",
    "\n",
    "def h(x, w, b):\n",
    "    return sigmoid(z(x, w, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then a loss function $l$ to calculate the squared error at a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l(x, w, b, y):\n",
    "    loss = (y - h(x, w, b))**2\n",
    "    print('loss', loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now let's see how our loss function changes as we change $w$ from .3 to .5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z =  0.6\n",
      "sigma =  0.6456563062257954\n",
      "loss 0.12555945331754728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12555945331754728"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l(1, .3, .3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z =  0.8\n",
      "sigma =  0.6899744811276125\n",
      "loss 0.0961158223520931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0961158223520931"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l(1, .5, .3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, great so by perhaps we can see that changing $w$ affects the output of the function: $J(w, b) = (y -  \\sigma(z(w, b)))^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that changing $w$ changes the output of $z$ which changes the output of the $\\sigma$ function, which changes the output of $J(w, b)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing the Chain Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in the last function, we can still calculate the derivative of a composite function like this by multiplying the derivatives of these nested functions together.\n",
    "\n",
    "So if we think of our function J(w, b) as:\n",
    "\n",
    "$J(w, b) = l(y, (\\sigma(z(w, b, x)))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is we should be able to find this derivative by calculating:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$J'(w, b) = l'*\\sigma'*z'$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we are finding the rate of change in with respect to $w$ and $b$, so let's express this as the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\delta J}{\\delta w} = \\frac{\\delta J}{\\delta \\sigma} \\frac{\\delta \\sigma}{\\delta z} \\frac{\\delta z}{\\delta w} $\n",
    "\n",
    "$\\frac{\\delta J}{\\delta b} = \\frac{\\delta J}{\\delta \\sigma} \\frac{\\delta \\sigma}{\\delta z} \\frac{\\delta z}{\\delta b} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let's take a moment to articulate the above.  The change in our cost function J as we change our parameter w, is the change that w produces on the linear function $z$, times the amount that a change in $z$ changes the output of the $\\sigma$, times the change that a change in $\\sigma$ changes J. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Break it down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can solve for the derivatives by calculating each of the components individually.\n",
    "\n",
    "$$\\frac{\\delta l}{\\delta \\sigma}, \\frac{\\delta \\sigma}{\\delta z}, \\frac{\\delta z}{\\delta w}, \\frac{\\delta z}{\\delta b}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Finding $\\frac{\\delta l}{\\delta \\sigma}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$l(\\sigma) = (y - \\sigma(z(w))^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\delta l}{\\delta \\sigma} = 2(y - \\sigma(z(w, b))*-1 = -2(y - \\sigma(z(w, b)) = 2(\\sigma(z(w, b) - y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can represent this in code as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_dsig(w, b, x, y):\n",
    "    return 2*(h(w, b, x) - y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Remember that $h(x) = \\sigma(z(w, b))$ so we use substitution above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Finding $\\frac{\\delta \\sigma}{\\delta z}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\sigma(z) = \\frac{1}{1 + e^{-z}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the derivative of the sigmoid function is something we could calculate from scratch, but it would take a while, and it will take us off track.  Let's just skip to the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\sigma'(z) = \\sigma(z(x))*(1 - \\sigma(z(x)))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Finding $\\frac{\\delta z}{\\delta w}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$z(w, b) = wx + b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\delta z}{\\delta w} = x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now we have found all of the derivatives necessary to find $\\frac{\\delta J}{\\delta w}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\delta J}{\\delta w} = \\frac{\\delta l}{\\delta \\sigma} \\frac{\\delta \\sigma}{\\delta z} \\frac{\\delta z}{\\delta w} = 2(\\sigma(z(x_i) - y_i)*\\sigma(z(x))(1 - \\sigma(z(x))) * x_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So from there we write this in code as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dJ_dw(w, b, x, i):\n",
    "    return dl_dsig(w, b, x, y)*dsig_dz(w, b, x, y)*dz_dw(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this is a perfectly valid way of calculating the derivative, but we'll generally see it written in code differently.  Here's how we normally see it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dJ_dw(w, b, x, i):\n",
    "    dJ_dsig = dl_dsig(w, b, x, y)\n",
    "    dJ_dz = dsig_dz(w, b, x, y)*dl\n",
    "    dJ_dw = dz_dw(x)*dJ_dz\n",
    "    return dw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we just did was rewrite our function so that we are finding each component's impact on our cost function $J(w, b)$.  So it's a realization that each derivative we found is a combination of the local derivative and the upstream derivative it affects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for example, looking at the last line of the code, we rewrote our derivative $\\frac{\\delta J}{\\delta w}$ as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\delta J}{\\delta w} =   \\frac{\\delta J}{\\delta z}*\\frac{\\delta z}{\\delta w}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this works because we already calculated $\\frac{\\delta J}{\\delta z}$ as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\delta J}{\\delta z} =  \\frac{\\delta J}{\\delta \\sigma}*  \\frac{\\delta \\sigma}{\\delta z} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we already calculated $\\frac{\\delta J}{\\delta \\sigma }$ as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's look at our code again.  This approach is called back propagation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dJ_dw(w, b, x, i):\n",
    "    dJ_dsig = dl_dsig(w, b, x, y)\n",
    "    dJ_dz = dsig_dz(w, b, x, y)*dl\n",
    "    dJ_dw = dz_dw(x)*dJ_dz\n",
    "    return dw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is that we calculate each function's impact on our cost function starting with the outermost layer.  Then as we move further down, we can calculate each derivative by calculating the local derivative and multiplying it by the upstream derivative a change in the function affects. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this allows us to write\n",
    "\n",
    "$\\frac{\\delta J}{\\delta w} =   \\frac{\\delta J}{\\delta z}*\\frac{\\delta z}{\\delta w}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"https://www.jigsawlabs.io/free\" style=\"position: center\"><img src=\"https://storage.cloud.google.com/curriculum-assets/curriculum-assets.nosync/mom-files/jigsaw-labs.png\" width=\"15%\" style=\"text-align: center\"></a>\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
