{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Hypothesis Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last lab we built out the weights and biases for the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we'll simply wrap the building of our layers in a couple of functions.  This way we're a little more familiar with it when we go to train the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecting our Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we know, we build weight matrices and bias vectors for a network that look like the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "z_1 & = W_1x + b_1 \\\\\n",
    "a_1 & = \\sigma(z_1) \\\\\n",
    "z_2 & = W_2a_1 + b_2 \\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automating the construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we have created a function that follows the general pattern for constructing the linear layers of a neural network.  We execute the function in the cell below.  See if you can understand what the function is doing.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "def init_model(n_features, neur_l1, neur_out):\n",
    "    W1 = np.random.randn(n_features, neur_l1) \n",
    "    b1 = np.zeros((1, neur_l1))\n",
    "    W2 = np.random.randn(neur_l1, neur_out) \n",
    "    b2 = np.zeros((1, neur_out))\n",
    "    model = {'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2}\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_features = 28*28 n_neurons_l1 = 3 n_neurons_ouput = 2 \n",
    "model = init_model(28*28, 15, 10)\n",
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then uncomment the `initial_model` to see if matrices and vectors constructed by the function match the weight matrices and bias vectors that you constructed in the previous lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The forward method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we just wrote a function that initializes the layers of our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['W1', 'b1', 'W2', 'b2'])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_model.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's write a function that automatically makes predictions based on these weights and biases.  Now the outputs from the linear layers just involves the dot products.  But the activation layers involve some non-linear functions.\n",
    "\n",
    "Let's define them below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sigma(z):\n",
    "    return 1/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(last_layer):\n",
    "    return np.exp(last_layer)/np.sum(np.exp(last_layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 784)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X, model):\n",
    "    W1, b1, W2, b2 = tuple(model.values())\n",
    "    Z1 = (X.dot(W1) + b1)\n",
    "    A1 = sigma(Z1)\n",
    "    Z2 = (A1.dot(W2) + b2)\n",
    "    predictions = softmax(Z2)\n",
    "    return (Z1, Z2, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 10)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward(X, model)[1].shape\n",
    "# (50, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Here we return the prediction $z_2$ from the model, as well as $z_1$ and $a_1$ as we will need them later when in computing the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1, b1, W2, b2 = tuple(model.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 10)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.random.randn(50, 28*28) # 28*28 = 784 pixels\n",
    "forward(X[:20], model)[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 50)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The last array shows our predictions ($z_2$) for our neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"https://www.jigsawlabs.io/free\" style=\"position: center\"><img src=\"https://storage.cloud.google.com/curriculum-assets/curriculum-assets.nosync/mom-files/jigsaw-labs.png\" width=\"15%\" style=\"text-align: center\"></a>\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
