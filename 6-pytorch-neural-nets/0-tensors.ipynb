{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy to Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we'll begin moving towards the Pytorch library.  We'll see how we can build linear layers in Pytorch as well as make use of non-linear layers.  Let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, we've initialized a new model with something like the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(n_features, neur_l1, neur_out):\n",
    "    W1 = np.random.randn(n_features, neur_l1) / np.sqrt(n_features)\n",
    "    b1 = np.zeros((1, neur_l1))\n",
    "    W2 = np.random.randn(neur_l1, neur_out) / np.sqrt(neur_l1)\n",
    "    b2 = np.zeros((1, neur_out))\n",
    "    model = {'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2}\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialized a set of weight matrices (`W1`, and `W2`) and bias vectors (`b1` and `b2`), which we later tune through our training procedure.  Once these weights and biases are trained, we can use them to make a prediction with our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Pytorch, we can do the same thing with a Pytorch tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "W1 = torch.randn(8, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1513, -0.0768, -0.3163,  ..., -1.3084, -0.2952, -1.2212],\n",
       "        [ 0.5460,  0.0042,  1.0023,  ...,  1.1528,  0.1197,  0.0430],\n",
       "        [ 0.4627, -1.6576, -2.6115,  ...,  0.6369, -1.8958,  1.0517],\n",
       "        ...,\n",
       "        [ 0.4963, -0.0175,  0.3728,  ..., -2.6316,  0.1751,  0.4416],\n",
       "        [ 0.6346,  1.1451,  0.7053,  ...,  0.6085,  0.0940, -1.5013],\n",
       "        [-0.2043,  1.0081,  0.3093,  ..., -1.3962,  0.3015,  0.8347]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 784])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the Pytorch library provides us with much of the same interface as numpy.  We can initialize data through the `randn` function, the `randint` function, or by creating our own custom array just like in numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can select our data by using the same bracket operators as we saw in numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1513, -0.0768, -0.3163],\n",
       "        [ 0.5460,  0.0042,  1.0023]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1[:2, :3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main difference between a pytorch tensor and a numpy array that we need to worry about at this point is reshaping our data.  In Pytorch, the method for changing the shape of the data is called `view`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.1513, -0.0768, -0.3163,  ..., -1.3962,  0.3015,  0.8347])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.view(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Operations in Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of neural networks, perhaps the most important thing to know is how to perform matrix algebra operations.  Remember that the whole point of initializing a weight matrix and a bias vector is to use them to calculate the linear output of each neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initialize some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 784])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = torch.randn(3, 784)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 784]), torch.Size([784, 3]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.shape, X.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -8.4259, -11.8295,  23.4698],\n",
       "        [-39.4412,  36.8929, -61.9721],\n",
       "        [-23.1415,  42.7091,  25.7792],\n",
       "        [ 33.3887, -11.9642,  13.4949],\n",
       "        [ 22.8652,   8.9591,  -3.2612],\n",
       "        [ -9.7971,  17.3862, -10.0517],\n",
       "        [ 12.3032, -52.7073,  32.4848],\n",
       "        [ 19.9870,  23.3461,  -0.5489]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1 @ X.T \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see above that we have eight outputs for each of our three observations, just like we saw before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to include the addition of a bias vector, we initialize a vector with eight rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0904],\n",
       "        [-1.2224],\n",
       "        [-0.6987],\n",
       "        [ 0.1317],\n",
       "        [ 1.6392],\n",
       "        [ 1.4074],\n",
       "        [ 0.4002],\n",
       "        [-0.1969]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1 = torch.randn(8, 1)\n",
    "b1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then add."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-10.5163, -13.9199,  21.3794],\n",
       "        [-40.6635,  35.6705, -63.1945],\n",
       "        [-23.8402,  42.0104,  25.0805],\n",
       "        [ 33.5204, -11.8325,  13.6266],\n",
       "        [ 24.5044,  10.5983,  -1.6220],\n",
       "        [ -8.3896,  18.7937,  -8.6443],\n",
       "        [ 12.7034, -52.3072,  32.8849],\n",
       "        [ 19.7900,  23.1491,  -0.7459]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z1 = W1 @ X.T  + b1\n",
    "Z1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So at this point, we can translate our `init_model` function to use Pytorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(n_features, neur_l1, neur_out):\n",
    "    W1 = torch.randn(n_features, neur_l1) / np.sqrt(n_features)\n",
    "    b1 = torch.zeros((1, neur_l1))\n",
    "    W2 = torch.randn(neur_l1, neur_out) / np.sqrt(neur_l1)\n",
    "    b2 = torch.zeros((1, neur_out))\n",
    "    model = {'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2}\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': tensor([[ 0.2883,  0.5991,  0.0466],\n",
       "         [-0.5802, -0.3250, -0.8185],\n",
       "         [ 0.4495, -0.1099,  0.4779],\n",
       "         [ 0.0704, -0.6322,  0.9711],\n",
       "         [ 0.7418, -0.4575, -0.1500]]),\n",
       " 'b1': tensor([[0., 0., 0.]]),\n",
       " 'W2': tensor([[-0.0307, -0.4393],\n",
       "         [-0.5518, -0.3604],\n",
       "         [-0.3678, -0.2677]]),\n",
       " 'b2': tensor([[0., 0.]])}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_model(5, 3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we learned about initializing the weight matrices and bias vectors of our neural network with Pytorch tensors.  As we saw, Pytorch tensors are similar to numpy arrays both in their construction and the operations we can perform with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We can initialize a Pytorch tensor in similar ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "W1 = torch.randn(8, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 784])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `view` method to reshape the tensore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2966, -0.7510,  0.9930,  ...,  1.9472, -0.3612,  0.0994])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.view(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And can perform matrix algebra operations with our tensor to pass our data through our linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.1926e+00,  2.8639e-03, -8.8633e+00],\n",
       "        [ 4.1558e+01, -3.9941e+01, -3.0199e+01],\n",
       "        [-1.3246e+01,  1.8456e+01,  2.3438e+01],\n",
       "        [-3.0452e+01, -2.8885e+01, -2.9598e+01],\n",
       "        [ 5.8378e+00, -4.2085e+01,  1.7439e+01],\n",
       "        [-1.4112e+01, -2.5177e+00,  3.6517e+01],\n",
       "        [-1.4192e+00, -3.1555e+01, -7.2901e+00],\n",
       "        [ 2.5637e+01,  5.2545e+01,  1.7124e+01]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z1 = W1 @ X.T  + b1\n",
    "Z1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
